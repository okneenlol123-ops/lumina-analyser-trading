# main.py
# Lumina Pro ‚Äî Deep Analyzer (Live Alpha Vantage + Roboflow Image Inference)
# Direkt eingebettete API-Keys (Benutzerwunsch)
FINNHUB_KEY = "d49pi19r01qlaebikhvgd49pi19r01qlaebiki00"
ALPHAV_KEY   = "22XGVO0TQ1UV167C"
ROBOFLOW_KEY = "rf_54FHs4sk2XhtAQly4YNOSTjo75B2"  # optional, nur wenn du Roboflow nutzen willst
ROBOFLOW_MODEL_PATH = "chart-pattern-detector/1"

# -------------------------
# Imports & Setup
# -------------------------
import streamlit as st
import json, os, time, random, io, urllib.request, urllib.parse, math, traceback
from datetime import datetime, timedelta
import statistics

# Pillow for image analysis
try:
    from PIL import Image, ImageOps, ImageStat, ImageFilter
    PIL_AVAILABLE = True
except Exception:
    PIL_AVAILABLE = False

# Streamlit page config
st.set_page_config(page_title="Lumina Pro ‚Äî Deep Analyzer", layout="wide", page_icon="üíπ")
st.markdown("""
<style>
html, body, [class*="css"] { background:#000 !important; color:#e6eef6 !important; }
.stButton>button { background:#111 !important; color:#e6eef6 !important; border:1px solid #222 !important; }
.card { background:#070707; padding:12px; border-radius:8px; border:1px solid #111; margin-bottom:12px; }
.small { color:#9aa6b2; font-size:13px; }
.badge { background:#111; color:#e6eef6; padding:6px 10px; border-radius:8px; border:1px solid #222; display:inline-block; }
</style>
""", unsafe_allow_html=True)

st.title("Lumina Pro ‚Äî Deep Analyzer (Live Alpha Vantage + Roboflow Image Inference)")

# -------------------------
# Utilities
# -------------------------
def now_iso(): return datetime.utcnow().isoformat() + "Z"

def internet_ok(timeout=3):
    try:
        urllib.request.urlopen("https://www.google.com", timeout=timeout)
        return True
    except Exception:
        return False

ONLINE = internet_ok()

CACHE_DIR = ".lumina_cache"
if not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR, exist_ok=True)

def cache_save(key, obj):
    try:
        with open(os.path.join(CACHE_DIR, key + ".json"), "w", encoding="utf-8") as f:
            json.dump({"ts": time.time(), "data": obj}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def cache_load(key, max_age=3600*24):
    try:
        path = os.path.join(CACHE_DIR, key + ".json")
        if not os.path.exists(path): return None
        with open(path, "r", encoding="utf-8") as f:
            obj = json.load(f)
        if time.time() - obj.get("ts",0) > max_age:
            return None
        return obj.get("data")
    except Exception:
        return None

# -------------------------
# HTTP helpers (Roboflow multipart)
# -------------------------
def encode_multipart(file_fieldname, filename, file_bytes, content_type="image/png"):
    boundary = '----WebKitFormBoundary' + ''.join(random.choice('0123456789abcdef') for _ in range(16))
    crlf = b'\r\n'
    body = bytearray()
    body.extend(b'--' + boundary.encode() + crlf)
    body.extend(f'Content-Disposition: form-data; name="{file_fieldname}"; filename="{filename}"'.encode() + crlf)
    body.extend(f'Content-Type: {content_type}'.encode() + crlf + crlf)
    body.extend(file_bytes + crlf)
    body.extend(b'--' + boundary.encode() + b'--' + crlf)
    content_type_header = f'multipart/form-data; boundary={boundary}'
    return content_type_header, bytes(body)

def roboflow_detect(image_bytes):
    if not ROBOFLOW_KEY:
        return None
    try:
        endpoint = f"https://detect.roboflow.com/{ROBOFLOW_MODEL_PATH}?api_key={urllib.parse.quote(ROBOFLOW_KEY)}"
        content_type, body = encode_multipart("file", "upload.png", image_bytes, "image/png")
        req = urllib.request.Request(endpoint, data=body, method="POST")
        req.add_header("Content-Type", content_type)
        req.add_header("User-Agent", "LuminaPro/1.0")
        with urllib.request.urlopen(req, timeout=30) as resp:
            raw = resp.read().decode("utf-8")
            return json.loads(raw)
    except Exception:
        return None

# -------------------------
# Market data fetchers (Finnhub & Alpha Vantage)
# -------------------------
def fetch_finnhub_candles(symbol: str, resolution: str = "5", from_ts: int = None, to_ts: int = None):
    if not FINNHUB_KEY:
        return None
    try:
        if to_ts is None: to_ts = int(time.time())
        if from_ts is None:
            if resolution in ("1","5","15","30","60"):
                from_ts = to_ts - 60*60*24
            else:
                from_ts = to_ts - 60*60*24*30
        params = {
            "symbol": symbol,
            "resolution": resolution,
            "from": str(int(from_ts)),
            "to": str(int(to_ts)),
            "token": FINNHUB_KEY
        }
        url = "https://finnhub.io/api/v1/stock/candle?" + urllib.parse.urlencode(params)
        with urllib.request.urlopen(url, timeout=25) as resp:
            raw = resp.read().decode("utf-8")
            data = json.loads(raw)
        if data.get("s") != "ok":
            return None
        ts = data.get("t", [])
        opens = data.get("o", [])
        highs = data.get("h", [])
        lows = data.get("l", [])
        closes = data.get("c", [])
        vols = data.get("v", [])
        candles=[]
        for i, t in enumerate(ts):
            try:
                dt = datetime.utcfromtimestamp(int(t))
            except Exception:
                dt = datetime.utcnow()
            candles.append({
                "t": dt,
                "open": float(opens[i]),
                "high": float(highs[i]),
                "low": float(lows[i]),
                "close": float(closes[i]),
                "volume": float(vols[i]) if vols and i < len(vols) else 0.0
            })
        return candles
    except Exception:
        return None

# Alpha Vantage: as backup (MINUTE intraday)
def fetch_alpha_minute(symbol: str, interval="5min", outputsize="compact"):
    if not ALPHAV_KEY:
        return None
    try:
        base = "https://www.alphavantage.co/query?"
        params = {"function":"TIME_SERIES_INTRADAY","symbol":symbol,"interval":interval,"outputsize":outputsize,"apikey":ALPHAV_KEY}
        url = base + urllib.parse.urlencode(params)
        with urllib.request.urlopen(url, timeout=25) as resp:
            raw = resp.read().decode("utf-8")
            data = json.loads(raw)
        # different format: "Time Series (5min)": { timestamp: { "1. open":.. } }
        key = None
        for k in data:
            if "Time Series" in k:
                key = k; break
        if key is None:
            return None
        series = data[key]
        candles=[]
        # sort timestamps ascending
        for ts in sorted(series.keys()):
            row = series[ts]
            dt = datetime.strptime(ts, "%Y-%m-%d %H:%M:%S")
            candles.append({
                "t": dt,
                "open": float(row["1. open"]),
                "high": float(row["2. high"]),
                "low": float(row["3. low"]),
                "close": float(row["4. close"]),
                "volume": float(row.get("5. volume",0))
            })
        return candles
    except Exception:
        return None

# offline simulated candles helper
def generate_simulated_candles(seed: str, periods: int, start_price: float = 100.0, resolution_minutes: int = 5):
    rnd = random.Random(abs(hash(seed)) % (2**31))
    p = float(start_price)
    prices=[]
    for _ in range(periods):
        drift = (rnd.random() - 0.49) * 0.003
        shock = (rnd.random() - 0.5) * 0.02
        p = max(0.01, p * (1 + drift + shock))
        prices.append(round(p,6))
    candles=[]
    now = datetime.utcnow()
    for i, prm in enumerate(prices):
        o = round(prm * (1 + random.uniform(-0.002,0.002)),6)
        c = prm
        h = round(max(o,c) * (1 + random.uniform(0.0,0.004)),6)
        l = round(min(o,c) * (1 - random.uniform(0.0,0.004)),6)
        t = now - timedelta(minutes=(periods - 1 - i) * resolution_minutes)
        candles.append({"t": t, "open": o, "high": h, "low": l, "close": c, "volume": random.randint(1,1000)})
    return candles

# -------------------------
# Indicators & pattern detectors
# -------------------------
def sma(values, period):
    res=[]
    for i in range(len(values)):
        if i+1 < period: res.append(None)
        else: res.append(sum(values[i+1-period:i+1])/period)
    return res

def ema(values, period):
    res=[]; k = 2.0/(period+1.0); prev=None
    for v in values:
        if prev is None: prev = v
        else: prev = v * k + prev * (1-k)
        res.append(prev)
    return res

def macd(values, fast=12, slow=26, signal=9):
    if not values: return [],[],[]
    ef = ema(values, fast); es = ema(values, slow)
    mac = [(a-b) if (a is not None and b is not None) else None for a,b in zip(ef, es)]
    mac_vals = [m for m in mac if m is not None]
    if not mac_vals: return mac, [None]*len(mac), [None]*len(mac)
    sig_vals = ema(mac_vals, signal)
    sig_iter = iter(sig_vals)
    sig_mapped=[]
    for v in mac:
        sig_mapped.append(None if v is None else next(sig_iter))
    hist = [(m-s) if (m is not None and s is not None) else None for m,s in zip(mac, sig_mapped)]
    return mac, sig_mapped, hist

def rsi(values, period=14):
    if len(values) < period+1: return [None]*len(values)
    deltas = [values[i] - values[i-1] for i in range(1,len(values))]
    gains = [d if d>0 else 0 for d in deltas]
    losses = [-d if d<0 else 0 for d in deltas]
    avg_gain = sum(gains[:period]) / period
    avg_loss = sum(losses[:period]) / period
    res = [None]*period
    for i in range(period, len(deltas)):
        avg_gain = (avg_gain*(period-1) + gains[i]) / period
        avg_loss = (avg_loss*(period-1) + losses[i]) / period
        rs = avg_gain / avg_loss if avg_loss != 0 else float('inf')
        val = 100 - (100 / (1 + rs))
        res.append(round(val,2))
    return res

# candlestick detectors
def is_doji(c):
    body = abs(c["close"] - c["open"])
    total = c["high"] - c["low"]
    return total > 0 and (body / total) < 0.15

def is_hammer(c):
    body = abs(c["close"] - c["open"])
    lower = min(c["open"], c["close"]) - c["low"]
    return body > 0 and lower > 2 * body

def is_shooting_star(c):
    body = abs(c["close"] - c["open"])
    upper = c["high"] - max(c["open"], c["close"])
    return body > 0 and upper > 2 * body

def is_bullish_engulfing(prev, cur):
    if not prev: return False
    return (cur["close"] > cur["open"]) and (prev["close"] < prev["open"]) and (cur["open"] < prev["close"]) and (cur["close"] > prev["open"])

def is_bearish_engulfing(prev, cur):
    if not prev: return False
    return (cur["close"] < cur["open"]) and (prev["close"] > prev["open"]) and (cur["open"] > prev["close"]) and (cur["close"] < prev["open"])

def detect_patterns(candles):
    patterns=[]
    n = len(candles)
    for i in range(1,n):
        cur=candles[i]; prev=candles[i-1]
        if is_bullish_engulfing(prev, cur): patterns.append(("Bullish Engulfing", i))
        if is_bearish_engulfing(prev, cur): patterns.append(("Bearish Engulfing", i))
        if is_hammer(cur): patterns.append(("Hammer", i))
        if is_shooting_star(cur): patterns.append(("Shooting Star", i))
        if is_doji(cur): patterns.append(("Doji", i))
    if n>=3:
        if (candles[-3]["close"] < candles[-3]["open"]) and is_doji(candles[-2]) and (candles[-1]["close"] > candles[-1]["open"]):
            patterns.append(("Morning Star", n-1))
        if (candles[-3]["close"] > candles[-3]["open"]) and is_doji(candles[-2]) and (candles[-1]["close"] < candles[-1]["open"]):
            patterns.append(("Evening Star", n-1))
    return patterns

# -------------------------
# Offline Image Analyzer (Main Focus)
# -------------------------
def analyze_chart_image_structure(image_bytes):
    """
    Very robust offline-only image structure analyzer.
    Input: image bytes of a candlestick chart screenshot.
    Output: dict with trend, patterns, volatility_estimate, confidence, recommendation, summary, internal metrics.
    """
    if not PIL_AVAILABLE:
        return {"error":"Pillow is not installed. Install pillow to use offline image analyzer."}
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("L")  # grayscale
    except Exception as e:
        return {"error":"Failed to open image."}
    # resize for consistent processing
    W,H = img.size
    maxw = 1400
    if W > maxw:
        img = img.resize((maxw, int(H * maxw / W)))
        W,H = img.size
    # focus crop: remove header/footer, keep main candle area
    left = int(W * 0.03); right = int(W * 0.97)
    top = int(H * 0.08); bottom = int(H * 0.78)
    chart = img.crop((left, top, right, bottom))
    chart = ImageOps.autocontrast(chart, cutoff=2)
    chart = chart.filter(ImageFilter.MedianFilter(size=3))
    pix = chart.load()
    Wc,Hc = chart.size
    # vertical darkness profile (candles/wicks produce darker columns)
    col_darkness = [0] * Wc
    for x in range(Wc):
        s = 0
        # sample every 2 pixels vertically to speed up
        for y in range(0, Hc, 2):
            s += 255 - pix[x,y]
        col_darkness[x] = s
    # smoothing window
    smooth = []
    for i in range(Wc):
        window = col_darkness[max(0,i-4):min(Wc,i+5)]
        smooth.append(sum(window)/len(window) if window else 0)
    avg = sum(smooth)/len(smooth) if smooth else 0.0
    # detect peaks/troughs
    peaks=[]; troughs=[]
    for i in range(2, Wc-2):
        if smooth[i] > smooth[i-1] and smooth[i] > smooth[i+1] and smooth[i] > avg*1.25:
            peaks.append(i)
        if smooth[i] < smooth[i-1] and smooth[i] < smooth[i+1] and smooth[i] < avg*0.6:
            troughs.append(i)
    peak_count = len(peaks); trough_count = len(troughs)
    density = peak_count / (Wc/100.0 + 1e-9)  # per 100px
    # left-right brightness trend -> heuristic
    left_mean = ImageStat.Stat(chart.crop((0,0,Wc//2,Hc))).mean[0]
    right_mean = ImageStat.Stat(chart.crop((Wc//2,0,Wc,Hc))).mean[0]
    trend = "Seitw√§rts"
    if right_mean < left_mean - 6:
        trend = "Abw√§rtstrend"
    elif right_mean > left_mean + 6:
        trend = "Aufw√§rtstrend"
    # pattern heuristics by local column shapes
    doji_like = 0; hammer_like = 0; engulfing_like = 0; shooting_like = 0
    sample_peaks = peaks[-min(80, len(peaks)):] if peaks else []
    for idx in sample_peaks:
        # sample column intensity vector
        col = [255 - pix[idx, y] for y in range(Hc)]
        maxv = max(col) if col else 0
        if maxv <= 0:
            continue
        thresh = max(2, maxv * 0.4)
        high_positions = [i for i,v in enumerate(col) if v >= thresh]
        if not high_positions:
            continue
        body_height = (max(high_positions) - min(high_positions)) if len(high_positions) > 1 else 0
        # doji: small body relative to height
        if body_height < Hc * 0.05:
            doji_like += 1
        # long lower shadow -> hammer-like (if darker near bottom)
        lower_shadow = Hc - 1 - max(high_positions)
        upper_shadow = min(high_positions) - 0
        if lower_shadow > body_height * 2.5 and body_height > 0:
            hammer_like += 1
        if upper_shadow > body_height * 2.5 and body_height > 0:
            shooting_like += 1
    # engulfing via successive peaks ratio
    if len(peaks) >= 2:
        for i in range(len(peaks)-1):
            a = peaks[i]; b = peaks[i+1]
            if smooth[b] > smooth[a] * 1.9:
                engulfing_like += 1
    # volatility estimate: variation of smoothed profile
    var = statistics.pvariance(smooth) if len(smooth) > 1 else 0.0
    vol_est = min(100.0, max(1.0, (var**0.5) / (avg+1e-9) * 200.0))
    # record patterns
    patterns=[]
    if doji_like: patterns.append(f"{doji_like}√ó Doji-like")
    if hammer_like: patterns.append(f"{hammer_like}√ó Hammer-like")
    if shooting_like: patterns.append(f"{shooting_like}√ó Shooting-star-like")
    if engulfing_like: patterns.append(f"{engulfing_like}√ó Engulfing-like")
    if peak_count > 12 and density > 6: patterns.append("Hohe Candle-Dichte")
    if trough_count > 6: patterns.append("Mehrere lokale Tiefs")
    if not patterns: patterns.append("Keine klaren Candle-Formen erkannt")
    # confidence heuristic
    conf = 30 + min(60, int(min(peak_count, 40) * 1.25 + len(patterns) * 5 + (10 if trend != "Seitw√§rts" else 0)))
    conf = max(5, min(98, conf))
    # scoring
    score = 0
    if trend == "Aufw√§rtstrend": score += 2
    if trend == "Abw√§rtstrend": score -= 2
    score += hammer_like * 2
    score += engulfing_like * 2
    score -= shooting_like * 2
    # interpret
    if score >= 3:
        rec = "Kaufen"
    elif score <= -2:
        rec = "Short"
    else:
        rec = "Neutral"
    # probability estimate
    prob = min(95.0, max(10.0, 45.0 + score * 9.0 + conf * 0.2))
    risk_pct = min(50.0, max(1.0, vol_est * 0.6))
    # build summary sentences
    summary=[]
    if rec == "Kaufen":
        summary.append(f"Strukturanalyse: {', '.join(patterns[:3])}. Trend: {trend}.")
        summary.append(f"Erfolgssch√§tzung: {prob:.1f}% ‚Ä¢ Gesch√§tztes Risiko: {risk_pct:.1f}%.")
        summary.append("Tipp: Kleine Long-Position mit Stop-Loss; warte Best√§tigung der n√§chsten Kerze.")
    elif rec == "Short":
        summary.append(f"Strukturanalyse: {', '.join(patterns[:3])}. Trend: {trend}.")
        summary.append(f"Erfolgssch√§tzung: {prob:.1f}% ‚Ä¢ Gesch√§tztes Risiko: {risk_pct:.1f}%.")
        summary.append("Tipp: Short mit enger Absicherung; beobachte Volumen.")
    else:
        summary.append("Keine eindeutige Struktur ‚Äî Markt neutral.")
        summary.append("Warte auf Best√§tigung (Breakout/Volume) bevor du ein Full-Size-Entry machst.")
        summary.append("Tipp: Setze keinen gro√üen Trade ohne weitere Signale.")
    return {
        "trend": trend,
        "patterns": patterns,
        "confidence": conf,
        "volatility": round(vol_est,2),
        "recommendation": rec,
        "probability": round(prob,1),
        "risk_pct": round(risk_pct,2),
        "summary": summary,
        "internal": {"peak_count": peak_count, "trough_count": trough_count, "density": round(density,2)}
    }

# -------------------------
# Backtesting (lightweight, local)
# -------------------------
def backtest_pattern_on_history(pattern_name, history_candles, lookahead=10):
    """
    Very lightweight backtest:
    - pattern_name: string like "Engulfing" or "Hammer"
    - history_candles: list of candles (older->newer)
    - lookahead: number of future candles to measure success
    Returns: dict with hits, total, avg_return, winrate
    """
    hits = 0; total = 0; returns = []
    n = len(history_candles)
    for i in range(2, n - lookahead):
        # naive detection: check last 3 candles at i for pattern
        window = history_candles[i-2:i+1]
        # create simple detectors
        try:
            prev, cur = window[-2], window[-1]
        except Exception:
            continue
        detected = False
        if pattern_name.lower().find("engulf") >= 0:
            if is_bullish_engulfing(prev, cur) or is_bearish_engulfing(prev, cur):
                detected = True
        if pattern_name.lower().find("hammer") >= 0:
            if is_hammer(cur):
                detected = True
        if pattern_name.lower().find("doji") >= 0:
            if is_doji(cur):
                detected = True
        if not detected:
            continue
        total += 1
        entry_price = cur["close"]
        future_price = history_candles[i + lookahead]["close"]
        ret = (future_price - entry_price) / (entry_price + 1e-12)
        returns.append(ret)
        if ret > 0:
            hits += 1
    winrate = (hits / total * 100.0) if total > 0 else 0.0
    avg_ret = (sum(returns) / len(returns) * 100.0) if returns else 0.0
    return {"pattern": pattern_name, "checked": total, "wins": hits, "winrate": round(winrate,2), "avg_return_pct": round(avg_ret,3)}

# -------------------------
# SVG candle renderer (for visualization)
# -------------------------
def render_svg_candles(candles, markers=None, stop=None, tp=None, width=1000, height=520):
    if not candles: return "<svg></svg>"
    n = len(candles)
    margin = 54
    chart_h = int(height * 0.62)
    max_p = max(c["high"] for c in candles)
    min_p = min(c["low"] for c in candles)
    pad = (max_p - min_p) * 0.08 if (max_p - min_p) > 0 else 1.0
    max_p += pad; min_p -= pad
    spacing = (width - 2*margin) / n
    candle_w = max(3, spacing * 0.6)
    def y(p): return margin + chart_h - (p - min_p) / (max_p - min_p) * chart_h
    svg = [f'<svg width="{width}" height="{height}" xmlns="http://www.w3.org/2000/svg">']
    svg.append(f'<rect x="0" y="0" width="{width}" height="{height}" fill="#07070a"/>')
    for i in range(6):
        yy = margin + i*(chart_h/5)
        price_label = round(max_p - i*(max_p-min_p)/5, 6)
        svg.append(f'<line x1="{margin}" y1="{yy}" x2="{width-margin}" y2="{yy}" stroke="#151515" stroke-width="1"/>')
        svg.append(f'<text x="{8}" y="{yy+4}" font-size="11" fill="#9aa6b2">{price_label}</text>')
    for i, c in enumerate(candles):
        cx = margin + i*spacing + spacing/2
        top = y(c["high"]); low = y(c["low"]); open_y = y(c["open"]); close_y = y(c["close"])
        color = "#00cc66" if c["close"] >= c["open"] else "#ff4d66"
        svg.append(f'<line x1="{cx}" y1="{top}" x2="{cx}" y2="{low}" stroke="#888" stroke-width="1"/>')
        by = min(open_y, close_y); bh = max(1, abs(close_y - open_y))
        svg.append(f'<rect x="{cx-candle_w/2}" y="{by}" width="{candle_w}" height="{bh}" fill="{color}" stroke="{color}" rx="1" ry="1"/>')
    if markers:
        for m in markers:
            i = m.get("idx", len(candles)-1)
            if i<0 or i>=n: continue
            cx = margin + i*spacing + spacing/2
            if m.get("type","").lower() == "buy":
                svg.append(f'<polygon points="{cx-8},{margin+8} {cx+8},{margin+8} {cx},{margin-2}" fill="#00ff88"/>')
            else:
                svg.append(f'<polygon points="{cx-8},{height-30} {cx+8},{height-30} {cx},{height-46}" fill="#ff7788"/>')
    if stop:
        try:
            sy = y(stop)
            svg.append(f'<line x1="{margin}" y1="{sy}" x2="{width-margin}" y2="{sy}" stroke="#ffcc00" stroke-width="2" stroke-dasharray="6,4"/>')
            svg.append(f'<text x="{width-margin-260}" y="{sy-6}" fill="#ffcc00" font-size="12">Stop: {stop}</text>')
        except Exception:
            pass
    if tp:
        try:
            ty = y(tp)
            svg.append(f'<line x1="{margin}" y1="{ty}" x2="{width-margin}" y2="{ty}" stroke="#66ff88" stroke-width="2" stroke-dasharray="4,4"/>')
            svg.append(f'<text x="{width-margin-260}" y="{ty-6}" fill="#66ff88" font-size="12">TP: {tp}</text>')
        except Exception:
            pass
    for i in range(0, n, max(1, n//10)):
        x = margin + i*spacing + spacing/2
        t = ""
        try:
            t = candles[i]["t"].strftime("%m-%d %H:%M")
        except:
            t = str(candles[i].get("t",""))
        svg.append(f'<text x="{x-36}" y="{height-6}" font-size="11" fill="#9aa6b2">{t}</text>')
    svg.append('</svg>')
    return "\n".join(svg)

# -------------------------
# Fusion: combine image analysis + market candles + backtest
# -------------------------
def fuse_image_and_market_analysis(img_res, candles):
    """
    img_res: output from analyze_chart_image_structure
    candles: list or None
    returns recommendation dict
    """
    rec = {
        "recommendation": img_res.get("recommendation", "Neutral"),
        "prob": img_res.get("probability", 50.0),
        "risk_pct": img_res.get("risk_pct", 5.0),
        "stop": None, "tp": None, "reasons": list(img_res.get("patterns",[])[:6]), "summary": img_res.get("summary",[])
    }
    if candles:
        last = candles[-1]["close"]
        closes = [c["close"] for c in candles]
        s20 = sum(closes[-20:])/20 if len(closes)>=20 else sum(closes)/len(closes)
        s50 = sum(closes[-50:])/50 if len(closes)>=50 else s20
        bias = 0
        if s20 > s50:
            bias += 1; rec["reasons"].append("SMA20 > SMA50")
        else:
            bias -= 1; rec["reasons"].append("SMA20 < SMA50")
        macd_line, macd_sig, _ = macd(closes)
        if macd_line and macd_sig and macd_line[-1] is not None and macd_sig[-1] is not None:
            if macd_line[-1] > macd_sig[-1]:
                bias += 1; rec["reasons"].append("MACD > Signal")
            else:
                bias -= 1; rec["reasons"].append("MACD < Signal")
        rec["prob"] = max(5.0, min(95.0, rec["prob"] + bias*6.0))
        # volatility
        if len(closes) >= 10:
            returns = [(closes[i]-closes[i-1])/closes[i-1] for i in range(1,len(closes))]
            vol = statistics.pstdev(returns) if len(returns) > 1 else 0.02
        else:
            vol = 0.02
        rec["risk_pct"] = min(50.0, max(0.5, vol*100*2.5))
        rec["stop"] = round(last * (1 - rec["risk_pct"]/100.0), 6)
        rec["tp"] = round(last * (1 + (rec["risk_pct"]/100.0)*2.0), 6)
    return rec

# -------------------------
# UI pages
# -------------------------
st.sidebar.title("Navigation")
page = st.sidebar.radio("Seiten", ["Home","Live Analyzer","Bild-Analyse (offline)","Backtest","Einstellungen","Hilfe"])

if not ONLINE:
    st.sidebar.error("‚ùå Keine Internetverbindung ‚Äî Live data wird simuliert")
else:
    st.sidebar.success("‚úÖ Internet verf√ºgbar")

# Home
if page == "Home":
    st.header("Lumina Pro ‚Äî Deep Analyzer")
    st.markdown("""
    **Hauptfunktionen**
    - Bild-Analyzer (offline): Lade einen Chart-Screenshot hoch ‚Äî die App analysiert automatisch Struktur, Muster, Volatilit√§t und gibt ein klares Fazit.
    - Live Analyzer: Analysiert echtes Marktdaten (Finnhub / Alpha Vantage) ‚Äî Candle-Visualisierung & Recommendation.
    - Backtest: Runnt leichtgewichtige Backtests f√ºr erkannte Muster.
    """)
    st.write("Pillow installiert:", PIL_AVAILABLE)
    st.write("Finnhub Key:", bool(FINNHUB_KEY))
    st.write("Alpha Vantage Key:", bool(ALPHAV_KEY))
    st.markdown("Tip: F√ºr beste Bild-Analyse croppe das Bild auf den reinen Kerzenbereich (ohne UI-Header).")

# Live Analyzer page
elif page == "Live Analyzer":
    st.header("Live Analyzer ‚Äî Symbol (Finnhub / Alpha Vantage fallback)")
    left,right = st.columns([3,1])
    with right:
        symbol = st.text_input("Symbol (z.B. BINANCE:BTCUSDT oder AAPL)", value="BINANCE:BTCUSDT")
        resolution = st.selectbox("Resolution (min)", ["1","5","15","30","60"], index=1)
        periods = st.slider("Candles", 30, 800, 240, step=10)
        fallback_price = st.number_input("Fallback Price", value=20000.0)
        run = st.button("Lade & Analysiere Symbol")
    with left:
        if run:
            candles = None
            if ONLINE and FINNHUB_KEY:
                to_ts = int(time.time()); from_ts = to_ts - int(periods) * int(resolution) * 60
                candles = fetch_finnhub_candles(symbol, resolution, from_ts, to_ts)
                if candles is None and ALPHAV_KEY:
                    st.warning("Finnhub lieferte keine Daten. Versuche Alpha Vantage (Fallback).")
                    av = fetch_alpha_minute(symbol, interval=resolution + "min" if resolution != "D" else "60min")
                    if av:
                        candles = av[-periods:] if len(av) >= periods else av
                if candles is None:
                    st.warning("Keine Live-Daten ‚Äî Simulation wird verwendet.")
                    candles = generate_simulated_candles(symbol + "_sim", periods, fallback_price, int(resolution))
                elif len(candles) < periods:
                    need = periods - len(candles)
                    pad = generate_simulated_candles(symbol + "_pad", need, candles[0]["open"] if candles else fallback_price, int(resolution))
                    candles = pad + candles
            else:
                st.info("Offline oder API-Keys fehlen ‚Äî Simulation wird verwendet.")
                candles = generate_simulated_candles(symbol + "_sim", periods, fallback_price, int(resolution))
            # compute rec from candles only
            closes = [c["close"] for c in candles]
            patt = detect_patterns(candles)
            heur = {"trend": "Aufw√§rtstrend" if sum(closes[-20:])/20 > sum(closes[-50:])/50 if len(closes)>=50 else "Seitw√§rts" else "Seitw√§rts", "notes": []}
            # fuse with neutral image result
            img_dummy = {"recommendation":"Neutral","probability":50.0,"risk_pct":5.0,"patterns":[], "summary":[]}
            rec = fuse_image_and_market_analysis(img_dummy, candles)
            st.subheader(f"{symbol} ‚Äî Live Analyse")
            st.markdown(f"**Aktueller Preis:** {candles[-1]['close']:.2f}")
            if rec["recommendation"].lower().startswith("kaufen"):
                st.success(rec["recommendation"])
            elif rec["recommendation"].lower().startswith("short"):
                st.error(rec["recommendation"])
            else:
                st.info(rec["recommendation"])
            st.markdown(f"Wahrscheinlichkeit: **{rec['prob']}%**  ‚Ä¢  Risiko: **{rec['risk_pct']}%**")
            st.markdown("**Begr√ºndung:**")
            for r in rec.get("reasons", [])[:8]: st.write("- " + r)
            st.markdown("**Kurz:**")
            for s in rec.get("summary", [])[:3]: st.write("- " + s)
            svg = render_svg_candles(candles[-160:], stop=rec.get("stop"), tp=rec.get("tp"))
            st.components.v1.html(svg, height=540)

# Bild-Analyse (offline) - MAIN FOCUS
elif page == "Bild-Analyse (offline)":
    st.header("Bild-Analyse ‚Äî Struktur & Muster (OFFLINE)")
    st.markdown("Lade ein Chart-Screenshot hoch. Die App macht automatisch alle Analysen (Muster, Volatilit√§t, Klassifikation) und liefert ein klares Fazit.")
    uploaded = st.file_uploader("Chart-Bild hochladen (PNG/JPG)", type=["png","jpg","jpeg"])
    analyze_btn = st.button("Analysiere Bild (automatisch)")
    if uploaded is None:
        st.info("Bitte lade ein Chartbild hoch (idealerweise nur Candles ohne UI-Header).")
    else:
        st.image(uploaded, use_column_width=True)
        if analyze_btn:
            img_bytes = uploaded.read()
            with st.spinner("Analysiere Bild (offline, Fokus Struktur & Muster)..."):
                img_res = analyze_chart_image_structure(img_bytes)
            if img_res.get("error"):
                st.error(img_res["error"])
            else:
                # build backtest with historical simulated or real data to evaluate detected patterns
                # Try to fetch historical candles for tiny backtest via Finnhub/Alpha if possible
                hist_candles = None
                if ONLINE and FINNHUB_KEY:
                    # attempt to guess a symbol: try BTCUSDT on Binance as generic crypto
                    try_symbols = ["BINANCE:BTCUSDT","AAPL","MSFT","SPY"]
                    for tsym in try_symbols:
                        hist = fetch_finnhub_candles(tsym, "5", int(time.time()) - 60*60*24*30, int(time.time()))
                        if hist and len(hist) > 200:
                            hist_candles = hist
                            break
                if hist_candles is None and ALPHAV_KEY:
                    try:
                        av = fetch_alpha_minute("AAPL","5min")
                        if av and len(av) > 200:
                            hist_candles = av
                    except Exception:
                        hist_candles = None
                if hist_candles is None:
                    hist_candles = generate_simulated_candles("backtest_seed", 800, 100.0, 5)
                # run backtests for top detected patterns
                backtests = []
                for p in img_res.get("patterns", [])[:4]:
                    name = p.split()[0]  # e.g. "Doji-like" -> "Doji-like"
                    res = backtest_pattern_on_history(name, hist_candles, lookahead=10)
                    backtests.append(res)
                # fuse image-only with market-simulated backtest insight to produce final rec
                # (no candles for symbol ‚Äî use image-only fusion)
                # we produce final recommendation: use img_res + summarize backtests
                final = {
                    "recommendation": img_res["recommendation"],
                    "probability": img_res["probability"],
                    "risk_pct": img_res["risk_pct"],
                    "summary": img_res["summary"],
                    "patterns": img_res["patterns"],
                    "confidence": img_res["confidence"],
                    "volatility": img_res["volatility"],
                    "backtests": backtests
                }
                # display UI similar to screenshot
                top1, top2 = st.columns([2,1])
                with top1:
                    if final["recommendation"] == "Kaufen":
                        st.success(f"Empfehlung: {final['recommendation']}  ‚Ä¢  {final['probability']}%")
                    elif final["recommendation"] == "Short":
                        st.error(f"Empfehlung: {final['recommendation']}  ‚Ä¢  {final['probability']}%")
                    else:
                        st.info(f"Empfehlung: {final['recommendation']}  ‚Ä¢  {final['probability']}%")
                    st.markdown(f"**Risiko (gesch√§tzt):** {final['risk_pct']}%")
                    st.markdown("**Kurzbefund (3 S√§tze):**")
                    for s in final["summary"][:3]:
                        st.write("- " + s)
                with top2:
                    st.markdown("**Details**")
                    st.write("Trend:", img_res["trend"])
                    st.write("Confidence:", str(img_res["confidence"]) + "%")
                    st.write("Volatility est.:", str(img_res["volatility"]) + "%")
                    st.write("Detected patterns:")
                    for p in img_res["patterns"][:8]:
                        st.write("- " + p)
                st.markdown("---")
                st.subheader("Backtest-Analyse (Background approximate)")
                if backtests:
                    for b in backtests:
                        st.write(f"{b['pattern']}: Checks={b['checked']} ‚Ä¢ Wins={b['wins']} ‚Ä¢ WinRate={b['winrate']}% ‚Ä¢ AvgRet={b['avg_return_pct']}%")
                else:
                    st.info("Keine Backtest-Daten verf√ºgbar.")
                # show a demo svg chart based on structural cues
                demo_candles = generate_simulated_candles("img_demo_" + str(img_res.get("internal",{}).get("peak_count",0)), 160, start_price=100.0, resolution_minutes=5)
                svg = render_svg_candles(demo_candles, width=1000, height=420)
                st.components.v1.html(svg, height=450)
                st.success("Bild-Analyse & Hintergrund-Backtest abgeschlossen.")

# Backtest page
elif page == "Backtest":
    st.header("Backtest / Simulation")
    st.markdown("W√§hle ein Muster und teste auf historische (simulierte) Daten.")
    pattern = st.selectbox("Muster ausw√§hlen", ["Bullish Engulfing","Bearish Engulfing","Hammer","Doji","Morning Star"])
    lookahead = st.slider("Lookahead (Kerzen)", 1, 30, 10)
    if st.button("Run Backtest"):
        hist = generate_simulated_candles("backtest_seed_2", 1000, 100.0, 5)
        res = backtest_pattern_on_history(pattern, hist, lookahead=lookahead)
        st.write(res)
        st.line_chart([c["close"] for c in hist[-200:]])

# Einstellungen
elif page == "Einstellungen":
    st.header("Einstellungen")
    st.write("Keys sind im Code eingebettet (unsicher). F√ºr Public-Hosting: nutze st.secrets oder Umgebungsvariablen.")
    st.write("Pillow installiert:", PIL_AVAILABLE)
    if st.button("Cache l√∂schen"):
        try:
            for f in os.listdir(CACHE_DIR):
                os.remove(os.path.join(CACHE_DIR, f))
        except Exception:
            pass
        st.success("Cache gel√∂scht")

# Hilfe
elif page == "Hilfe":
    st.header("Hilfe & Tipps")
    st.markdown("""
    - Bild-Analyzer ist offline und fokussiert auf Struktur (keine Symbolidentifikation).
    - Lade saubere Charts (Kerzenbereich, keine Overlays) f√ºr beste Ergebnisse.
    - Live Analyzer nutzt Finnhub / AlphaVantage (API limits beachten).
    - Empfehlungen sind probabilistische Sch√§tzungen ‚Äî **keine Anlageberatung**.
    """)
    st.markdown("Recommended upgrades:")
    st.write("- Persistente Speicherung von Analysen (Audit).")
    st.write("- Verbesserte Roboflow-Model-Mapping (falls Remote-Labels verf√ºgbar).")
    st.write("- Erweiterter Backtester mit Geb√ºhren & Slippage.")

# footer
st.markdown("---")
st.caption("Lumina Pro ‚Äî Deep Analyzer. Keys are embedded per user request. Recommendations are probabilistic estimates and not financial advice.")
